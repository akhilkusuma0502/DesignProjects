{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpeechEmotionRecognition.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOB+bLx9fhRom+R3Fmk5fng",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhilkusuma0502/DesignProjects/blob/master/SpeechEmotionRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls_bTlgAlioF",
        "colab_type": "text"
      },
      "source": [
        "# Speech Emotion Recognition\n",
        "Speech Emotion Recognition, abbreviated as SER, is the act of attempting to recognize human emotion and affective states from speech. This is capitalizing on the fact that voice often reflects underlying emotion through tone and pitch. This is also the phenomenon that animals like dogs and horses employ to be able to understand human emotion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ytgsZGOnXCK",
        "colab_type": "text"
      },
      "source": [
        "Download DatSet from [Here](https://drive.google.com/file/d/1wWsrN2Ep7x6lWqOXfr4rpKGYrJhWc8z7/view)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auJJ5La6ZpBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install librosa soundfile numpy sklearn pyaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tZTTmxznbu_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwBATz1rfegj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "local_zip = '/tmp/speech-emotion-recognition-ravdess-data.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/ravdess-data')\n",
        "zip_ref.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivBG5O2mhSsJ",
        "colab_type": "text"
      },
      "source": [
        "Install required libraries .. In this case we need librosa to extract features like mfcc,chroma, mel.\n",
        "we numpy to represent features as numpy vectors and we need glob to iterate all sound files.\n",
        "\n",
        "**librosa is a Python library for analyzing audio and music. It has a flatter package layout, standardizes interfaces and names, backwards compatibility, modular functions, and readable code.**\n",
        "\n",
        "we also need to split the data in to train and test sets.\n",
        "\n",
        "We are using MLPClassifier from skleran library neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9T3NHsmSY82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KfsI4kEmPvx",
        "colab_type": "text"
      },
      "source": [
        "# **Speech Emotion Recognition â€“ Objective**\n",
        "## To build a model to recognize emotion from speech using the librosa and sklearn libraries and the RAVDESS dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKaWl6cKhxJt",
        "colab_type": "text"
      },
      "source": [
        "The below function takes input a soundfile. Here all the soundfiles are of .wav types.\n",
        "Set the mfcc,chroma and mel to True while calling the function.\n",
        "Extract features like sample rate and initalize a numpy array to store the feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6jNwHcBZ1VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting features(mfcc,chroma,mel) from a sound file.\n",
        "def extract_feature(file_name, mfcc, chroma, mel):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate = sound_file.samplerate\n",
        "        if chroma:\n",
        "            stft = np.abs(librosa.stft(X))\n",
        "        result = np.array([])\n",
        "        if mfcc:\n",
        "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "            result = np.hstack((result, mfccs))\n",
        "        if chroma:\n",
        "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "            result = np.hstack((result, chroma))\n",
        "        if mel:\n",
        "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n",
        "            result = np.hstack((result, mel))\n",
        "    return result"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c79rFMYjiO5v",
        "colab_type": "text"
      },
      "source": [
        "The below is a dictionary defined with values as keys to represent emotions of the speech. These are taken from Filenames.\n",
        "Observed emotions are emotions that are observed in the speech."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbiwVVmSfOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotions = {\n",
        "    '01': 'neutral',\n",
        "    '02': 'calm',\n",
        "    '03': 'happy',\n",
        "    '04': 'sad',\n",
        "    '05': 'angry',\n",
        "    '06': 'fearful',\n",
        "    '07': 'disgust',\n",
        "    '08': 'surprised'\n",
        "}\n",
        "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP3Zx8f8ip0J",
        "colab_type": "text"
      },
      "source": [
        "The below function load data  and returns a split data to train and test variables. The default test size for this 0.2 and also it uses extract_features function to extract mel,chroma and mfcc and stoores in feature variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxk2cW0ASkuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(test_size=0.2):\n",
        "    x, y = [], []\n",
        "    for file in glob.glob(\"/tmp/ravdess-data/**/*.wav\"):\n",
        "        file_name = os.path.basename(file)\n",
        "        emotion = emotions[file_name.split(\"-\")[2]]\n",
        "        if emotion not in observed_emotions:\n",
        "            continue\n",
        "        feature = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "        x.append(feature)\n",
        "        y.append(emotion)\n",
        "    return train_test_split(np.array(x), y,train_size =1-test_size, test_size=test_size, random_state=9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryVV3LuYjCnJ",
        "colab_type": "text"
      },
      "source": [
        "Call the load_data() function which will return 4 variables x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nb3WvEmSnXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = load_data()\n",
        "print((x_train.shape[0], x_test.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLZOZXwqjLFQ",
        "colab_type": "text"
      },
      "source": [
        "Lets see the shape of the features extracted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFR4fowRkM1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e57d27e5-2782-4b38-f47a-0d79905809db"
      },
      "source": [
        "print(f'Features extracted: {x_train.shape[1]}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features extracted: 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNa0vqWnjPSi",
        "colab_type": "text"
      },
      "source": [
        "Data Preprocessing is Done.\n",
        "All we need is to create a classifier with MLP(Multi Layer perceptron) Neural Network.\n",
        "Initalize it with alpha=0.01, batch_size=256, epsilon=1e-08\n",
        "Provide number of hidden layers\n",
        "and learning rate to adaptive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yy9H6ZhkRPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=MLPClassifier(alpha=0.01,\n",
        "                    batch_size=256, \n",
        "                    epsilon=1e-08,\n",
        "                    hidden_layer_sizes=(300,), \n",
        "                    learning_rate='adaptive', \n",
        "                    max_iter=500)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrME29bQkeOo",
        "colab_type": "text"
      },
      "source": [
        "Fit the training data to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q48EEdEekTY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "beb57012-0f9c-4323-b8ff-57c1f4d299b8"
      },
      "source": [
        "model.fit(x_train,y_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.01, batch_size=256, beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(300,), learning_rate='adaptive',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOsrA9KkkdOC",
        "colab_type": "text"
      },
      "source": [
        "Pass the X_test data to predict and store it in Y_Pred."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq-RZxVPkX1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=model.predict(x_test)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPm85sgPkqRx",
        "colab_type": "text"
      },
      "source": [
        "From Metrics import Accuracy_score and pass y_test and predicted values to get the accuracy score on Test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kry-2ZoTkb6o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0cb483d5-2d9d-48d7-ef8d-c9ca985ce42e"
      },
      "source": [
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 71.43%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWabs0AIk3N3",
        "colab_type": "text"
      },
      "source": [
        "We got 71 % Accuracy. That means out of 10 files we feed to our network , it predicts 7 acuurate and 3 inaccurate. Which is good model as of now.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**SER is tough because emotions are subjective and annotating audio is challenging.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ljQRJLXmhVp",
        "colab_type": "text"
      },
      "source": [
        "# Lets Predict with a Single item from our test set to recognize the feeling of the speech."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1cyqBCelNRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7d5d230-8f22-4ded-fd54-81048a6de837"
      },
      "source": [
        "model.predict([x_test[3]])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['happy'], dtype='<U7')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3_8qlSnmsdh",
        "colab_type": "text"
      },
      "source": [
        "# It Predicted Happy"
      ]
    }
  ]
}